{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1990d2-71b1-4dc8-bd0b-880f1b81216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from easyocr import Reader\n",
    "import time\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1fd9673-3c9a-43c2-a594-440ce3579e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(image, model, display=False):\n",
    "    start = time.time()\n",
    "    # pass the image through the model and get the detections\n",
    "    detections = model.predict(image)[0].boxes.data\n",
    "\n",
    "    # check to see if the detections tensor is not empty\n",
    "    if detections.shape != torch.Size([0, 6]):\n",
    "\n",
    "        # initialize the list of bounding boxes and confidences\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        classes = []\n",
    "\n",
    "        # loop over the detections\n",
    "        for detection in detections:\n",
    "            # extract the confidence (i.e., probability) associated\n",
    "            # with the prediction\n",
    "            confidence = detection[4]\n",
    "\n",
    "            # filter out weak detections by ensuring the confidence\n",
    "            # is greater than the minimum confidence\n",
    "            if float(confidence) < CONFIDENCE_THRESHOLD:\n",
    "                continue\n",
    "\n",
    "            # if the confidence is greater than the minimum confidence, add\n",
    "            # the bounding box and the confidence to their respective lists\n",
    "            boxes.append(detection[:4])\n",
    "            confidences.append(detection[4])\n",
    "            classes.append(detection[5])\n",
    "\n",
    "        print(f\"{len(boxes)} Number plate(s) have been detected.\")\n",
    "        # initialize a list to store the bounding boxes of the\n",
    "        # number plates and later the text detected from them\n",
    "        number_plate_list= []\n",
    "\n",
    "        # loop over the bounding boxes\n",
    "        for i in range(len(boxes)):\n",
    "            # extract the bounding box coordinates\n",
    "            xmin, ymin, xmax, ymax = int(boxes[i][0]), int(boxes[i][1]),int(boxes[i][2]), int(boxes[i][3])\n",
    "            # append the bounding box of the number plate\n",
    "            number_plate_list.append([[xmin, ymin, xmax, ymax],confidences[i]],classes[i])\n",
    "\n",
    "            # draw the bounding box and the label on the image\n",
    "            cv2.rectangle(image, (xmin, ymin), (xmax, ymax), COLOR, 2)\n",
    "            text = \"{}: {:.2f}%\".format(classes[i],confidences[i] * 100)\n",
    "            cv2.putText(image, text, (xmin, ymin - 5),cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLOR, 2)\n",
    "\n",
    "            if display:\n",
    "                # crop the detected number plate region\n",
    "                number_plate = image[ymin:ymax, xmin:xmax]\n",
    "                # display the number plate\n",
    "                cv2.imshow(f\"Number plate {i}\", number_plate)\n",
    "\n",
    "        end = time.time()\n",
    "        # show the time it took to detect the number plates\n",
    "        print(f\"Time to detect the number plates: {(end - start) * 1000:.0f} milliseconds\")\n",
    "        # return the list containing the bounding\n",
    "        # boxes of the number plates\n",
    "        return number_plate_list\n",
    "    # if there are no detections, show a custom message\n",
    "    else:\n",
    "        print(\"No number plates have been detected.\")\n",
    "        return []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5348579-e1eb-43f4-96c6-4e265276a9b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'YOLO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mYOLO\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.jpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(file_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'YOLO' is not defined"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"best.pt\")\n",
    "\n",
    "file_path = \"1.jpeg\"\n",
    "\n",
    "image = cv2.imread(file_path)\n",
    "\n",
    "list = detect(image, model)\n",
    "\n",
    "if(list == []):\n",
    "    print(\"No number plates have been detected.\")\n",
    "else:\n",
    "    for item in list:\n",
    "        print(item[5])\n",
    "    \n",
    "cv2.imshow('Image', image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77ba356-a0fd-40c6-baeb-3d652d0cc404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaenv",
   "language": "python",
   "name": "condaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
